{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snxSUWXD7q_p"
   },
   "source": [
    "# Практическая работа №3\n",
    "### Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-8OLsAV7wrQ"
   },
   "source": [
    "Как было рассказано на лекции, стохастический градиентый спуск сходится быстрее, чем полный, хотя и менее стабильно. В этом задании вам предлагается реализовать стохастический градиентный спуск и сравнить его с точным вычислением весов линейной модели по скорости работы и значению метрики качества."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IgQyWw5o7Nej",
    "ExecuteTime": {
     "end_time": "2024-11-04T16:23:25.142772Z",
     "start_time": "2024-11-04T16:23:25.115794800Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ],
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGD1wQgMruJw"
   },
   "source": [
    "### Задание 0\n",
    "\n",
    "Реализуйте класс ```LinearRegressionSGD``` c обучением и и применением линейной регрессии, построенной с помощью стохастического градиентного спуска, с заданным интерфейсом."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QZxdV27R9-uc",
    "ExecuteTime": {
     "end_time": "2024-11-04T16:23:25.177938800Z",
     "start_time": "2024-11-04T16:23:25.132705400Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LinearRegressionSGD(BaseEstimator):\n",
    "    def __init__(self, epsilon=1e-4, max_steps=100, w0=None, alpha=1e-4):\n",
    "        \"\"\"\n",
    "        epsilon: разница для нормы изменения весов\n",
    "        max_steps: максимальное количество шагов в градиентном спуске\n",
    "        w0: np.array (d,) - начальные веса\n",
    "        alpha: шаг обучения\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon\n",
    "        self.max_steps = max_steps\n",
    "        self.w0 = w0\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.w_history = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array (l, d)\n",
    "        y: np.array (l)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        l, d = X.shape\n",
    "        self.w = self.w0 if self.w0 is not None else np.zeros(d)\n",
    "        \n",
    "        for step in range(self.max_steps):\n",
    "            # Случайный выбор индекса\n",
    "            idx = np.random.randint(l)\n",
    "            X_i = X[idx]\n",
    "            y_i = y[idx]\n",
    "\n",
    "            # Вычисление градиента\n",
    "            gradient = self.calc_gradient(X_i, y_i)\n",
    "\n",
    "            # Обновление весов\n",
    "            self.w -= self.alpha * gradient\n",
    "            self.w_history.append(self.w.copy())\n",
    "\n",
    "            # Проверка условия сходимости\n",
    "            if np.linalg.norm(gradient) < self.epsilon:\n",
    "                break\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: np.array (l, d)\n",
    "        ---\n",
    "        output: np.array (l)\n",
    "        \"\"\"\n",
    "        return X @ self.w\n",
    "\n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array (d,)\n",
    "        y: float\n",
    "        ---\n",
    "        output: np.array (d)\n",
    "        \"\"\"\n",
    "        error = (X @ self.w) - y\n",
    "        gradient = error * X\n",
    "        return gradient\n"
   ],
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNOm9-bXpdT3"
   },
   "source": [
    "Проверять работу мы будем на имеющемся в sklearn наборе данных boston: в нём нужно по информации о доме предсказать его стоимость."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c24JCwes9-pe",
    "ExecuteTime": {
     "end_time": "2024-11-04T16:23:26.439383400Z",
     "start_time": "2024-11-04T16:23:25.142772Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка Boston Housing Data из внешнего источника\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "\n",
    "# Обработка данных\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])  # Признаки\n",
    "target = raw_df.values[1::2, 2]  # Целевая переменная\n",
    "\n",
    "# Разделение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=10)\n",
    "\n",
    "# Создание и обучение модели\n",
    "model_sgd = LinearRegressionSGD(alpha=1e-7, max_steps=1000)\n",
    "model_sgd.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание и оценка качества\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model_sgd.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"MSE на тестовой выборке:\", mse)\n"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE на тестовой выборке: 95.59030917889521\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eIJwWnInXnr"
   },
   "source": [
    "### Задание 1\n",
    "\n",
    "Метрикой качества в нашей задаче будет MAPE - Mean Absolute Percentage Error. Реализуйте её с заданным интефейсом и вычислите\n",
    "```MAPE(y_test, y_0)```, где ```y_0 = (mean(y_test), mean(y_test), ...)```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "znoDavxyuLsi",
    "ExecuteTime": {
     "end_time": "2024-11-04T16:23:26.480347400Z",
     "start_time": "2024-11-04T16:23:26.437868700Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "def MAPE(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true: np.array (l)\n",
    "    y_pred: np.array (l)\n",
    "    ---\n",
    "    output: float [0, +inf)\n",
    "    \"\"\"\n",
    "    # Вычисляем MAPE, избегая деления на ноль\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e6mTAykeojwp",
    "ExecuteTime": {
     "end_time": "2024-11-04T16:23:26.488785200Z",
     "start_time": "2024-11-04T16:23:26.452035200Z"
    }
   },
   "source": [
    "# Создаем y_0, состоящий из среднего значения y_test\n",
    "y_0 = np.full_like(y_test, fill_value=np.mean(y_test))\n",
    "\n",
    "# Вычисляем MAPE\n",
    "mape_result = MAPE(y_test, y_0)\n",
    "print(\"MAPE(y_test, y_0):\", mape_result)"
   ],
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(y_test, y_0): 37.41588297684096\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nNy2ITxuMKf"
   },
   "source": [
    "### Задание 2\n",
    "\n",
    "Обучите ```LinearRegressionSGD``` с базовыми параметрами на тренировочном наборе данных (```X_train```, ```y_train```), сделайте предсказание на тестовых данных ```X_test```, записав результат в переменную ```y_pred_sgd```  и вычислите ошибку MAPE."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7BIHwAwUvB-N",
    "ExecuteTime": {
     "end_time": "2024-11-04T16:23:26.491496900Z",
     "start_time": "2024-11-04T16:23:26.466504500Z"
    }
   },
   "source": [
    "# Инициализация модели с базовыми параметрами\n",
    "sgd = LinearRegressionSGD()\n",
    "\n",
    "# Обучение модели на тренировочных данных\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred_sgd = sgd.predict(X_test)\n",
    "\n",
    "# Вычисление MAPE\n",
    "mape_sgd = MAPE(y_test, y_pred_sgd)\n",
    "print(\"MAPE(y_test, y_pred_sgd):\", mape_sgd)\n"
   ],
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(y_test, y_pred_sgd): 4.826894101380071e+147\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWappMdMtIPV"
   },
   "source": [
    "### Задание 3\n",
    "\n",
    "Вычислите веса по точной формуле, используя ```X_train``` и ```y_train```; предскажите с их помощью целевую переменную на ```X_test```, записав результат в переменную ```y_pred_lr``` и вычислите ошибку MAPE."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wjMUlPje9-k0",
    "ExecuteTime": {
     "end_time": "2024-11-04T16:23:26.496444200Z",
     "start_time": "2024-11-04T16:23:26.485240700Z"
    }
   },
   "source": [
    "# Добавление столбца единиц для смещения (bias) в X_train и X_test\n",
    "X_train_b = np.hstack((np.ones((X_train.shape[0], 1)), X_train))  # Добавляем bias к обучающим данным\n",
    "X_test_b = np.hstack((np.ones((X_test.shape[0], 1)), X_test))     # Добавляем bias к тестовым данным\n",
    "\n",
    "# Вычисление весов по точной формуле\n",
    "w_exact = np.linalg.inv(X_train_b.T @ X_train_b) @ X_train_b.T @ y_train\n",
    "\n",
    "# Предсказание с использованием точных весов\n",
    "y_pred_lr = X_test_b @ w_exact\n",
    "\n",
    "# Вычисление MAPE\n",
    "mape_lr = MAPE(y_test, y_pred_lr)\n",
    "print(\"MAPE(y_test, y_pred_lr):\", mape_lr)\n"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE(y_test, y_pred_lr): 17.39197284954152\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yL9L-4cwxZho"
   },
   "source": [
    "## Бонусное задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZFaUn7yx04u"
   },
   "source": [
    "До этого вы релизовывали модели, в которых не было штрафа за величину весов ```w```. Как было рассказано ранее в лекциях, это может привести к неустойчивости модели и переобучению. Чтобы избежать этих эффектов, предлагается добавить к оптимизируемому функционалу L2-норму весов; таким образом, будем решать задачу гребневой регрессии, Ridge:\n",
    "\n",
    "$$ \\frac{1}{l}(Xw-y)^T(Xw-y) +\\gamma||w||_2 \\rightarrow \\min_{w}. $$\n",
    "\n",
    "### Задание 4\n",
    "Реализуйте обучение такой модели в матричном виде (смотрите дополнительные материалы к этой неделе) с помощью стохастического градиентного спуска. Класс должен совпадать по набору реализованных функций с ```LinearRegressionVectorized```, разница будет лишь в параметре $\\gamma$, отвечающем за степень регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TEXqBqmGxWDz",
    "ExecuteTime": {
     "end_time": "2024-11-04T16:23:26.559716600Z",
     "start_time": "2024-11-04T16:23:26.496444200Z"
    }
   },
   "source": [],
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6t9rqXFu8Pq6"
   },
   "source": [
    "Так же, как и в основном задании, обучите модель с базовыми параметрами на тренировочных данных и сделайте прогноз y_pred_ridge. Выведите значение MAPE(y_test, y_pred_ridge)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6A2hak_A8QPO",
    "ExecuteTime": {
     "end_time": "2024-11-04T16:23:26.566571400Z",
     "start_time": "2024-11-04T16:23:26.515954100Z"
    }
   },
   "source": [],
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T16:23:26.571676200Z",
     "start_time": "2024-11-04T16:23:26.532153900Z"
    }
   }
  }
 ]
}
